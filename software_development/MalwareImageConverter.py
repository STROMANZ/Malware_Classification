#!/usr/bin/python3
import numpy as np
import os
from tensorflow import keras
from PIL import Image
from sklearn.model_selection import train_test_split
from skmultilearn.model_selection import iterative_train_test_split
from skmultilearn.model_selection.measures import get_combination_wise_output_matrix
import pandas as pd
from collections import Counter

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

dimen = 32

dir_path = "dataset"
output_path = "images_for_learning"

dir_path = dir_path + "/" 
output_path = output_path + "/" 

sub_dir_list = os.listdir(dir_path)
images = list()
labels = list()
for i in range(len(sub_dir_list)):
    label = i
    image_names = os.listdir(dir_path + sub_dir_list[i])
    for image_path in image_names:
        path = dir_path + sub_dir_list[i] + "/" + image_path
        image = Image.open(path).convert('L')
        resize_image = image.resize((dimen, dimen))
        array = list()
        for x in range(dimen):
            sub_array = list()
            for y in range(dimen):
                sub_array.append(resize_image.load()[x, y])
            array.append(sub_array)
        image_data = np.array(array)
        image = np.array(np.reshape(image_data, (dimen, dimen, 1))) / 255
        images.append(image)
        labels.append(label)
        print(path, label)

x = np.array(images)
y = np.array(keras.utils.to_categorical(np.array(labels), num_classes=len(sub_dir_list)))

# Split the Dataset test_size 0.2 equals the 80:20 ratio (20%)
#train_features, validation_features, train_labels, validation_labels = train_test_split(x, y, test_size=0.2, random_state=40)
train_features, train_labels, validation_features, validation_labels = iterative_train_test_split(x, y, test_size=0.05)

df_train_labels = pd.DataFrame(data=train_labels)
df_validation_labels = pd.DataFrame(data=validation_labels)

print("LABEL" + "\t\t" + "TRAINING_NO" + "\t" + "VALIDATION_NO")
for item in range(len(sub_dir_list)):
    print("Label " + str(item) + ":\t" + str(int(df_train_labels[item].sum())) + "\t\t" + str(int(df_validation_labels[item].sum()))) 


# Full Dataset
np.save('{}full-features.npy'.format(output_path), x)
np.save('{}full-labels.npy'.format(output_path), y)

# Training Dataset
np.save('{}train-features.npy'.format( output_path ), train_features)
np.save('{}train-labels.npy'.format( output_path ), train_labels)

# Validation Dataset
np.save('{}validation-features.npy'.format( output_path ), validation_features)
np.save('{}validation-labels.npy'.format( output_path ), validation_labels)
